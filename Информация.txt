- Поднимаем виртуалку, пишем баш скрипт, выбираем любую апи со стрим дата источниками 
Пишем сервис НА ЧЕМ УГОДНО, который подписывается и подсасывает данные, агрегирует и через log4j или 
совместимый http appender и закидывает напрямую в elastic.
В баш скрипте зафигачивается вся инфраструктура. В идеале чтобы этот скрипт скачивал проект с гита, 
ставил все что нужно и запускал - то есть автоматизировал вообще все. Бизнес логика не важна

- Выбираем любую апи со стрим дата источниками: 
    твиттер (ловить события типа добавление/удаление сообщения)
(можно с гита взять пример, так как там может быть готовый токен разработчика(сейчас получить сложнее);
    можно найти компактную приложуху и допилить, чтобы она генерила постоянный 
поток событий
    криптовалюты, где можно отвлеживать как меняется курс отношения одной валюты к другой
    система мониторинга какой-то облачной инфраструктуру, где меняется загруженность сервера

 - Нужно выполнить сбор и агрегацию сообщение, метрик, поступающих событий и скинуть в систему 
мониторинга либо файл из которого достанут, обработают статистику и построют график по периоду времени - 
какие-то диаграмки или графики, что происходило в течении минуты/пяти минут.

Главное чтобы источник был публично доступен. Хорошая документация у твиттер апи, но принципы у 
всех одинаковые
Докер нельзя (это вариант 3) для виртуалок (virsh утилити, kvm автоматизацию). 
Управление виртуалкой с хоста